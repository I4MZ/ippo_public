import os
import asyncio
from typing import Any

import uvicorn
from fastapi import FastAPI, Body, WebSocket, WebSocketDisconnect, File, UploadFile
from starlette.websockets import WebSocketState
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from queue import Queue
from pydantic import BaseModel
import tempfile

from api_key import openai_api_key
from langchain.agents import AgentType, initialize_agent
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler
from langchain.schema import LLMResult
from langchain.chains.llm import LLMChain
# from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.utilities.dalle_image_generator import DallEAPIWrapper

# vision ì‚¬ìš©
from google.cloud import vision
from google.cloud import vision_v1
import tempfile

# ë²ˆì—­
from google.cloud import translate_v2 as translate
translator = translate.Client()


os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'back/fastapi/glim/example/i4mz-vision-key.json'
vision_client = vision.ImageAnnotatorClient()

from query_data import get_prompt

from openai import OpenAI
openai_client = OpenAI(api_key=openai_api_key)
import requests
import time
from PIL import Image
import tempfile

app = FastAPI()
origins = [ "*" ]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

child_id = 1
child_name = "ìš°ì² "
# initialize the agent (we need to do this for the callbacks)
llm = ChatOpenAI(
    openai_api_key=openai_api_key,
    model_name="gpt-4-1106-preview",
    streaming=True,  # ! important
    callbacks=[]  # ! important (but we will add them later)
)
# ìœ ì €ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
user_memory = {}
def get_or_create_memory(child_id):
    if child_id not in user_memory:
        # user_memory[child_id] = ConversationBufferWindowMemory(memory_key="chat_history", k=5, return_messages=True, output_key="output")
        user_memory[child_id] = ConversationBufferWindowMemory(memory_key="chat_history", k=5, return_messages=True)
    return user_memory[child_id]

memory = get_or_create_memory(child_id=child_id)
prompt = get_prompt(child_name)

chain = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory
)

class AsyncCallbackHandler(AsyncIteratorCallbackHandler):
    # content: str = ""
    # final_answer: bool = False

    def __init__(self) -> None:
        super().__init__()

    async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        if token is not None and token != "":
            self.queue.put_nowait(token)


async def run_call(query: str, stream_it: AsyncCallbackHandler):
    # assign callback handler
    chain.llm.callbacks = [stream_it]
    # agent.agent.llm_chain.llm.callbacks = [stream_it]
    # now query
    await chain.acall(inputs={"keyword_text": query})

# request input format
class Query(BaseModel):
    text: str

async def create_gen(query: str, stream_it: AsyncCallbackHandler):
    task = asyncio.create_task(run_call(query, stream_it))
    async for token in stream_it.aiter():
        yield token
    await task

# client ë³„ WebSocket ì—°ê²° ê´€ë¦¬ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
active_websockets = {}
# WebSocket endpoint
@app.websocket("/chat")
async def websocket_chat(websocket: WebSocket):
    await websocket.accept()
    active_websockets[child_id] = websocket
    stream_it = AsyncCallbackHandler()

    async def receive_and_process(websocket: WebSocket):
        while websocket.application_state == WebSocketState.CONNECTED and websocket.client_state == WebSocketState.CONNECTED:
            try:
                # WebSocketì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ 
                data = await websocket.receive_text()
                await run_call(data, stream_it)
            except Exception as e:
                print(f"Error input text: {e}")
                break

    async def send_streaming_response(websocket: WebSocket):
        try:
            async for token in stream_it.aiter():
                # Check if the WebSocket is still connected before sending
                if websocket.application_state != WebSocketState.CONNECTED or websocket.client_state != WebSocketState.CONNECTED:
                    break
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ WebSocketìœ¼ë¡œ ì „ì†¡
                await websocket.send_text(token)
        except Exception as e:
            print(f"Error send data: {e}")
        finally:
            if websocket.application_state == WebSocketState.CONNECTED and websocket.client_state == WebSocketState.CONNECTED:
                await websocket.close()
            active_websockets.pop(child_id, None)
    # ë‘ ë¹„ë™ê¸° ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
    try:
        receive_task = asyncio.create_task(receive_and_process(websocket))
        send_task = asyncio.create_task(send_streaming_response(websocket))
        await asyncio.gather(receive_task, send_task)
    except Exception as e:
        print(f"WebSocket error: {e}")
    finally:
        if websocket.application_state == WebSocketState.CONNECTED and websocket.client_state == WebSocketState.CONNECTED:
            await websocket.close()
        active_websockets.pop(child_id, None)

HEART_BEAT_INTERVAL = 5
async def is_websocket_active(ws: WebSocket) -> bool:
    if not (ws.application_state == WebSocketState.CONNECTED and ws.client_state == WebSocketState.CONNECTED):
        return False
    try:
        await asyncio.wait_for(ws.send_json({'type': 'ping'}), HEART_BEAT_INTERVAL)
        message = await asyncio.wait_for(ws.receive_json(), HEART_BEAT_INTERVAL)
        assert message['type'] == 'pong'
    except BaseException:  # asyncio.TimeoutError and ws.close()
        return False
    return True

@app.get("/health")
async def health():
    """Check the api is running"""
    return {"status": "ğŸ¤™"}



@app.post("/record")
async def record(audio: UploadFile = File(...)):
    print("type: ", audio.content_type)
    contents = await audio.read()  # íŒŒì¼ ë°ì´í„°ë¥¼ ì½ìŒ

    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
        temp_file.write(contents)
        temp_file_path = temp_file.name

    # Whisper ëª¨ë¸ì— ì ìš©
    with open(temp_file_path, 'rb') as file_to_send:
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1",
            file=file_to_send
        )

    # ê²°ê³¼ ë°˜í™˜
    return {"transcript": transcript}


@app.post("/vision")
async def process_image(picture: UploadFile = File(...)):
    print("vision ì§„ì…")
    contents = await picture.read()

    image = vision_v1.types.Image(content=contents)

    try:
        response = vision_client.label_detection(image=image)
        labels = response.label_annotations
        descriptions = [label.description for label in labels]

        # ë²ˆì—­
        translated_descriptions = [translator.translate(desc, target_language='ko')['translatedText'] for desc in descriptions]
        print("Translated Descriptions:", translated_descriptions)

    except Exception as e:
        print("Error during image analysis:", e)
        translated_descriptions = []

    return {"descriptions": translated_descriptions}


# JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ê¸° ìœ„í•œ Pydantic ëª¨ë¸ ì •ì˜
class Description(BaseModel):
    sceneDescription: str  # JSON ë°ì´í„°ì— ìˆëŠ” í•„ë“œ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

import openai

@app.post("/generate_image")
def generate_and_download_image(sceneDescription : Description):
    image_style_keywords = "Please use bright and colorful visuals. The colors should be pastel, giving the image a soft, pleasant atmosphere. The characters in the scene should be well-detailed and joyful."

    # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
    visual_storytelling_prompt = (
        f"ì´ë¯¸ì§€ëŠ” ì˜¤ë¡œì§€ ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§ ìš”ì†Œì—ë§Œ ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤."
        f"ë°°ê²½, ìºë¦­í„°, í–‰ë™ì€ ì‹œê°ì ìœ¼ë¡œë§Œ ê°ì •ê³¼ ìƒí™©ì„ ì „ë‹¬í•  ìˆ˜ ìˆë„ë¡ ë¬˜ì‚¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
        f"ì´ì „ ì¥ë“¤ì˜ ìŠ¤íƒ€ì¼ê³¼ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©°, ì•„ì´ë“¤ì˜ ìƒìƒë ¥ì„ ìê·¹í•  ìˆ˜ ìˆëŠ” ìˆœìˆ˜í•œ ì‹œê°ì  ê²½í—˜ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."
    )
    image_prompt = (
        f"{visual_storytelling_prompt} "
        f"4ì„¸ì—ì„œ 7ì„¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë™í™”ì…ë‹ˆë‹¤."
        f"ì´ë¯¸ì§€ ë‹¹ í•˜ë‚˜ì˜ ì¥ë©´ë§Œ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
        f"Descriptive scene: {sceneDescription}"
        f"This image must be in the {image_style_keywords} style"
        f"(ì¤‘ìš”) ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬!! ê·¸ë¦¼ì—ëŠ” í…ìŠ¤íŠ¸ê°€ í‘œì‹œë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤."
        # f"Previous chapters' contents and images: {' '.join([obj.content for obj in previous_chapters['chat_history']])}"
    )

    try:
        response = openai.Image.create(
            model="dall-e-3",
            prompt=image_prompt,
            n=1,
            size="1024x1024"
        )
        # ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ì˜ url
        image_url = response['data'][0]['url']
        image_path = download_image(image_url)
        return FileResponse(image_path, headers={"Content-Type": "image/png"})
    except Exception as e:
        print(f"Error in API call: {e}")
        return None


# ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥í•˜ëŠ” ì—­í• 
def download_image(image_url, format="jpg"):
    response = requests.get(image_url)
    if response.status_code == 200:
        os.makedirs('images', exist_ok=True)

        base_name = "image"
        current_time = int(time.time())
        file_name = f"{base_name}_{current_time}.{format}"
        file_path = os.path.join('images', file_name)

        # íŒŒì¼ ì´ë¦„ ì¤‘ë³µ í™•ì¸ ë° ì²˜ë¦¬
        counter = 2
        while os.path.exists(file_path):
            file_name = f"{base_name}_{current_time}_{counter}.{format}"
            file_path = os.path.join('images', file_name)
            counter += 1

        with open(file_path, 'wb') as file:
            file.write(response.content)
        print("image donwload done!")
        return file_path
    else:
        raise Exception("Failed to download the image.")

if __name__ == "__main__":
    uvicorn.run(
        "websocket_server:app",
        host="localhost",
        port=8000
    )